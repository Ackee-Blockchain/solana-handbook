{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"handbook/appendixA/","title":"Appendix A - Ecosystem","text":""},{"location":"handbook/appendixB/","title":"Appendix B - NFTs","text":""},{"location":"handbook/appendixC/","title":"Appendix C - Gaming","text":""},{"location":"handbook/chapter1/block/","title":"Block","text":"<p>Block is a data structure that contains a header comprising three items \u2013 the hash of the previous block\u2019s header, metadata and a Merkle root [5]. Metadata depends on the protocol. The Merkle root is a root of the well-known Merkle tree, which can be used to verify later that transactions in a block have not been tampered with. After the header comes the core part of the block, the transaction.</p>"},{"location":"handbook/chapter1/blockchain/","title":"Blockchain","text":"<p>A blockchain can be thought of as a series of blocks or an append-only data structure that resembles an ordered back-linked linked list, which uses hashes as pointers to previous blocks (Figure 1.1). This structure consists of blocks that form a chain, hence the term blockchain. It can be easily concluded that it is a very simple data structure.</p> <p></p>"},{"location":"handbook/chapter1/coin/","title":"Coin","text":"<p>Coins motivate participation in the network. They are usually paid with every new block to miners or validators for their help in securing the network. Without the proper incentives, any decentralized blockchain network falls apart.</p>"},{"location":"handbook/chapter1/consensus/","title":"Consensus","text":"<p>To agree on a certain state of a blockchain, network nodes need to reach a consensus. We assume there are malicious nodes in the network. Therefore, the system must be able to withstand not only simple node failures but also attacks to a certain extent. BFT (Byzantine Fault Tolerant) is thus a desired property of such a distributed system. Currently, only three viable consensus families can be used in practice. The first is the classic PBFT-like (Practical BFT) algorithm family [6]. The second is a so-called Nakamoto consensus, which couples a Sybil protection mechanism of Proof-of-Work with the longest-chain rule, a novel consensus invented by Satoshi Nakamoto for Bitcoin in 2008 [2]. The third and newest family of consensus protocols known today is called Snow. Yet it is better known by its implementation name \u2013 Avalanche Consensus [7], introduced in 2018 and used for the Avalanche cryptocurrency.</p>"},{"location":"handbook/chapter1/nodes/","title":"Nodes","text":"<p>Node is a term from graph theory or distributed systems; it is a single participant in a network. The nodes communicate with each other according to the protocol and in a P2P manner forming the whole blockchain network. There might be more types of nodes that are not equal, e.g., validator nodes securing the network or pure RPC (Remote Procedure Call) nodes used only to query the network and post new transactions. Their functions may overlap.</p>"},{"location":"handbook/chapter1/protocol/","title":"Protocol","text":"<p>Protocol is a common set of rules network nodes must follow. It defines things like communication between P2P (Peer-to-Peer) nodes, transaction format for everyone intending to use the network, any special features, and everything else for the network to operate correctly and for the users to know how to transact over the network. An essential part of a good protocol for a decentralized blockchain network is the proper incentive setup; this creates the need for its native coin.</p>"},{"location":"handbook/chapter1/security/","title":"Security","text":"<p>Consensus and Sybil resistance mechanism are often confused as the same thing, which is not true and is worth pointing out. One works in conjunction with the other. Let\u2019s look at how this works in both PoW-based and PoS-based networks. Consider what makes Bitcoin, a PoW-based network, theoretically secure \u2013 it is the fact that only the longest chain is respected, also commonly known as the longest chain rule. This is why the consensus is called, as mentioned before, the Nakamoto consensus. For a PoS-based network, the Sybil resistance mechanism is usually associated with a variant of a PBFT-like algorithm or the novel Avalanche consensus.</p>"},{"location":"handbook/chapter1/smart-contract/","title":"Smart Contract","text":"<p>A smart contract is a piece of code deployed on a blockchain with a cryptographically signed transaction. Users can then interact with it by sending transactions that invoke a specific function defined in the smart contract and the business logic is executed as stated in the deployed code [9]. Data relevant to the smart contract state are also stored on the blockchain. Hence we can look at smart contracts as programs on a decentralized computer that access files in its file system and modify them according to the predefined rules. If such a contract is made immutable, we can trust that the smart contract will not do anything else than what it is supposed to do. It is worth noting that apart from storing the blockchain itself, each node creates a state as a result of transaction execution. The final state is the result of all processed transactions and can always be deterministically recreated from the blockchain history. Code is compiled for a predefined ISA (Instruction Set Architecture) and executed in a VM (Virtual Machine) which understands it. The mentioned VM is a special runtime environment similar to well-known VMs such as JVM (Java Virtual Machine) or CLR (Common Language Runtime) from Microsoft\u2019s .NET ecosystem. The most commonly known VM for smart contracts, which is used by Ethereum [3], is EVM (Ethereum Virtual Machine); it includes its very own instruction set specialized for the needs of smart contracts. Only transactions involving smart contract execution need to be processed by the VM. The standard execution path is to prepare the relevant smart contract data and smart contract byte code, launch the VM with said data and code, and observe possible failures. If the execution succeeds, the changes to the smart contract data made in the VM are taken, and the state outside the VM is changed; otherwise, the changes are discarded and the next transaction continues.</p>"},{"location":"handbook/chapter1/sybil-resistance/","title":"Sybil Resistance","text":"<p>To prevent a single entity from taking over the network, there must be a mechanism put in place so that no one can just spawn more nodes that can mine or vote (depending on the network) and thus subvert the network reputation system. These dishonest nodes would be able to out-vote honest nodes and start censoring transactions, approving invalid transactions, or changing the entire protocol. Currently, the two most common Sybil resistance mechanisms are PoW (Proof-of-Work) and PoS (Proof-of-Stake). The former employs a model where miners in the network are given a chance to mine a block that is proportional to their hashing power in the network and is used in Bitcoin [8]. The latter is a new type of model for voting-based networks, where a validator is given the power of their vote proportionally to staked coins.</p>"},{"location":"handbook/chapter1/transaction/","title":"Transaction","text":"<p>Transaction is a protocol-defined message that is stored as a part of a block, which is then stored as a part of a blockchain. The content usually consists of some kind of value transfer or on-chain program execution. Transactions are cryptographically signed by their authors, proving their authenticity. In the case of a value transfer, ownership of the funds or tokens often represents some value in the real world.</p>"},{"location":"handbook/chapter2/comparison-to-ethereum/","title":"Comparison to Ethereum","text":"<p>Solana is a smart contract platform. Compared to Ethereum, smart contracts on Solana are called Programs. They can be executed in parallel. Parallelization is one of the key differences from other platforms. While Ethereum can be considered a single-threaded distributed computing platform, Solana can be viewed as a multi-threaded one.</p> <p>Solana makes itself clear to focus on improving scalability from the engineering perspective. It is rethinking and reengineering core parts that were first seen in Ethereum and making them parallel and optimized, including the usage of Nvidia CUDA to speed up certain parts of the code and invent its own specialized horizontally scalable database system for state storage and other things that are supposed to make it possible to reach maximum TPS practically only bounded by the network throughput, memory throughput and the number of CUDA cores in modern Nvidia GPUs. Therefore over time, it should scale with better hardware available on the market and internet connectivity in the world.</p>"},{"location":"handbook/chapter2/rust-development/","title":"Rust Development","text":"<p>Solana\u2019s ecosystem revolves around the Rust programming language and its ecosystem. The main and only implementation of the node software is written in it. Also, Solana programs are almost exclusively written in Rust. Although there is no technical barrier preventing from using C or C++, Rust is the most supported language for developing on Solana. All the libraries and supporting code that can be found are written in it, leaving practically no other option.</p>"},{"location":"handbook/chapter3/","title":"Core Concepts","text":"<p>There are eight core concepts introduced in Solana that are supposed to make it as fast as developers claim. This section tries to cover them in as much detail as possible. Unfortunately, finding a proper explanation of some of the details is not always possible. Some of these are not yet or not fully implemented, so the source code does not answer the questions that arise while studying them.</p>"},{"location":"handbook/chapter3/archivers/","title":"Archivers \u2013\u2060 Distributed Ledger Storage","text":"<p>Given that the Solana blockchain can grow at enormous speed, considering a full capacity of 1 Gbps (with no overhead) for 365 days, it is roughly 4 petabytes of data that each node would need to store to have a complete history. There is a concept of a distributed ledger storage that would store this data in a decentralized fashion for everyone else.</p> <p>The idea is to offload the data from validators to these specialized network nodes. The data is split into many small pieces and replicated so that the full state can always be reconstructed. These specialized nodes are also contested on the protocol level to ensure they store the data they are supposed to store, and the data loss is prevented.</p> <p>This concept is yet to be implemented. A potential implementation might be using a new decentralized protocol for permanent storage Arweave or Filecoin.</p>"},{"location":"handbook/chapter3/cloudbreak/","title":"Cloudbreak \u2013\u2060 Horizontally-scalable Database","text":"<p>With fast computation, the obvious thing that becomes the new bottleneck is the memory. For example, the industry-standard local database for storing blockchain and state, LevelDB, does not support parallel reads and writes. That is fine for Bitcoin or Ethereum, but not for a massively parallel system like Solana.</p> <p>We could ask the question, why not store everything in RAM? It is too big; even for enterprise machines and large servers, this becomes impossible over time. Therefore Solana had to invent its own database system that supports parallel reads and writes and scales easily with more disks.</p> <p>This new database system is called Cloudbreak and makes use of memory-mapped files. The data is therefore stored in files that can be accessed independently. A memory-mapped file is a file that is mapped to the process\u2019 virtual memory address space and can be accessed directly without further system calls. The speed is still limited by the disk I/O, but we get less overhead, and the kernel can store a part of it in its page cache (also known as file cache).</p> <p>Reads in Cloudbreak are randomly distributed among available disks, as the data is stored evenly. Writes in Cloudbreak use the Copy-on-Write semantics and are appended to a random disk. Hence we get the speed of sequential writing. This is all possible thanks to a clever system of bookkeeping. Old data entries are also garbage collected for future use.</p> <p>The design of Cloudbreak makes it ideal for hardware setups, such as RAID 0 with fast NVMe SSDs. The Cloudbreak database was benchmarked by the Solana team. The results show that even with 10 million accounts (unit of data storage on Solana that will be described in the Programming model), a size that does not fit in the RAM (i.e., cannot be cached by page cache in the kernel), Cloudbreak still achieves reads and writes close to 1 million with a single SSD [15].</p>"},{"location":"handbook/chapter3/gulf-stream/","title":"Gulf Stream \u2013\u2060 Transaction Forwarding Protocol","text":"<p>Gulf Stream is Solana\u2019s mempool-less solution for forwarding and storing transactions before processing them.</p> <p>In traditional blockchains, each node reserves a part of its memory for the memory pool. This memory pool, more commonly referred to as mempool, is used to store transactions currently being broadcasted over the network but have not been processed and added to the blockchain as a part of a new block yet.</p> <p>This implies a huge communication overhead where every transaction must reach every other node in the network. While not everyone necessarily needs to be aware of all transactions in the mempool, they are the most important for miner and validator nodes (depending on the type of a network), which must include them in new blocks.</p> <p>If there are more transactions in the mempool than can fit in the block, the backlog of transactions is created. This can generally lead to increased transaction fees for users who need to push their transaction ahead of other transactions, as it is economically viable for the nodes securing the network to prefer transactions with higher fees. This is currently not possible on Solana, but on the other hand, the network is so fast with its ~400ms block rate that the aim is to process all remaining transactions almost instantaneously anyway.</p>"},{"location":"handbook/chapter3/gulf-stream/#the-solution","title":"The Solution","text":"<p>The solution that Solana devised is to avoid having a single shared mempool and instead push transactions to the edge of the network to the expected leader. The leader receives the transaction as quickly as possible and can process it immediately.</p> <p>However, this solution has a catch. The expected leader must be known ahead. Leaders are known in advance; their rotation is a function of the blockchain data and is known one full epoch before. An epoch is the number of slots for which one leader\u2019s schedule is valid. It is set to 432,000 slots, and with a ~400ms block rate, it takes about two days.</p>"},{"location":"handbook/chapter3/pipelining/","title":"Pipelining \u2013 Transaction Processing Optimizations","text":"<p>It is not enough to be able to form a consensus and share a block with the rest of the network quickly. A node must validate and execute all those transactions in received blocks before another block comes.</p> <p>For this reason, the Solana team developed something called the Transaction Processing Unit (TPU) [14]. The TPU works as a processor and extensively uses pipelining, a common CPU optimization that helps keep the chip more utilized by splitting an instruction execution into stages. It is a general way to keep all the hardware parts busy instead of idle. This concept of pipelining was borrowed, and that is how the TPU was born.</p> <p>The pipeline stages of TPU are following (Figure 1.6): - Data fetch in kernel space via network card (I/O) - Signature verification using GPU (very computation heavy if not offloaded) - Change of the state using CPU (banking) - Write to the disk in kernel space and send out via network card (I/O)</p> <p></p> <p>In fact, there are two TPUs in the Solana node software. The one called TPU is used for creating a new block, and the second one, TVU, where the V stands for validator or validation, is used for validating. They may slightly differ. However, the concept and functionality are very similar.</p>"},{"location":"handbook/chapter3/proof-of-history/","title":"Proof-of-History (PoH) \u2013\u2060 Virtual Clocks","text":"<p>Agreement on time in distributed systems has always been problematic. First, a high-level overview of this concept is described, followed by an in-depth description. Solana leverages the so-called Proof-of-History (PoH) mechanism to synchronize local virtual clocks on all nodes [10]. PoH ensures that the timestamp in any message can be trusted and that any timeouts in the consensus protocol can be avoided because everyone knows the time and knows whether to start a new round of consensus or not. PoH allows minimizing the block time as there\u2019s no waiting overhead. In other words, thanks to synchronized clocks, communication can be replaced by local computation. To prevent validators from skipping the validator that comes before them, PoH is used to force all validators to spend a minimum amount of time before they can even submit their block. Thus, if validator B follows validator A, B cannot attempt to skip A by chaining off its previous block because B has to run the Proof-of-History algorithm at least as long as A does, so A gets a fair chance to submit their block.</p>"},{"location":"handbook/chapter3/proof-of-history/#verifiable-delay-function-vdf","title":"Verifiable Delay Function (VDF)","text":"<p>PoH is based on a Verifiable Delay Function (VDF). Specifically, Solana uses a recursive pre-image resistant SHA256 VDF, where the output of one SHA256 iteration is recursively used as the next iteration\u2019s input. To create a block, the producer needs to compute the VDF with all new messages to be included in the block:</p> <pre><code>Message1 \u2192 Hash1\nHash1 + Message2 \u2192 Hash2\nHash2 + Message3 \u2192 Hash3\n\u2026\nHashn-1 + Messagen \u2192 Hashn\n</code></pre> <p>Observations:</p> <ul> <li>From PoH, we have a proof of the Lower Bound on the time of Messagei (i.e., Messagei must have taken place after Hashi\u22121).</li> <li>From PoH, we have a proof of the Upper Bound on the time of Messagei (i.e., Messagei must have taken place before Hashi).</li> <li>Points 1 and 2 prove the exact order of the messages, which implies that VDF not only provides us virtual clocks, but everyone can trust the order of events.</li> </ul> <p>Phases of PoH:</p> <ul> <li>Evaluation phase (leader): computation on only one CPU core as it is a strictly sequential computation by definition. This takes:</li> </ul> \\[ \\frac{total\\_number\\_of\\_hashes}{hashes\\_per\\_second\\_for\\_single\\_core} \\] <p>Total number of hashes Hashes per second for 1 core</p> <ul> <li>Verification phase (voters): the block can be checked in parallel using GPU with thousands of cores as it can be easily sliced and the intermediate hashes are known; this takes:</li> </ul> \\[ \\frac{total\\_number\\_of\\_hashes}{hashes\\_per\\_second\\_for\\_single\\_core * number\\_of\\_cores\\_available} \\] <p>Thus, it can be concluded that PoH is difficult to produce but easy to verify. These are two important factors that are crucial for the use of PoH \u2013\u2060 it is not easy to falsify the PoH, but once it is finished, any validator can verify the results very quickly.</p>"},{"location":"handbook/chapter3/sealevel/","title":"Sealevel \u2013\u2060 Parallel Smart Contract Runtime","text":"<p>Other blockchains are single-threaded global state machines. The only thing they might do in parallel is signature verification. Solana introduced Sealevel, a parallelized transaction processing engine designed to scale horizontally across GPUs and SSDs.</p> <p>Sealevel can theoretically process as many transactions as many cores are available to the system. According to the source code, Sealevel is not yet parallelized on the GPU level.</p> <p>This is a major improvement that makes Solana a multi-threaded global state machine, a thing not seen until Solana. Other blockchains, including the leading Ethereum, can be considered single-threaded global state machines because only one smart contract invocation can be processed at a time.</p> <p>The reason this is possible with Solana is that each and every Solana transaction describes all the states required to read and write to. Sealevel can then choose non-overlapping instructions to be executed in parallel and not only that. Transactions that only read certain states can be executed in parallel as well.</p> <p>This is a high-level description of how it works: - Sort millions of pending transactions. - Schedule all the non-overlapping transactions in parallel.</p>"},{"location":"handbook/chapter3/sealevel/#simd-approach-with-gpus","title":"SIMD approach with GPUs","text":"<p>There is a great potential for GPU parallelization and leveraging its SIMD capability. For example, in Nvidia CUDA, modern cards have thousands of CUDA cores and tens of Streaming Multiprocessors.</p> <p>When a CPU invokes a kernel grid, the blocks of threads are distributed among streaming multiprocessors and executed using specific ALU execution units, usually called CUDA cores and other SFUs (special function units).</p> <p>The executed code is the same for all cores. Imagine a situation where there is a single smart contract invocation but with numerous different inputs. This exact workload can be efficiently executed on GPU architectures, such as Nvidia CUDA.</p> <p>Since Sealevel is not yet optimized for GPU offloading, GPUs today are only used to accelerate PoH and signature verification and only if it is available to the system and the algorithm decides it is worth the overhead of launching the kernel grid.</p>"},{"location":"handbook/chapter3/sealevel/#bpf-berkeley-packet-filter","title":"BPF \u2013 Berkeley Packet Filter","text":"<p>There is one important thing that has not been covered in Sealevel yet. What actually executes the code, and how it is done. The standard way is to use some sort of a Virtual Machine (VM) and compile the code for it from any supported language. This code gets deployed to the blockchain, and when the user sends a transaction invoking this contract, the code gets loaded into the VM and executed.</p> <p>Ethereum does this using its own Ethereum Virtual Machine (EVM). Some other blockchains make use of Web Assembly (WASM). Solana iterated through all possible solutions and chose an unexpected VM called Berkeley Packet Filter (BPF).</p> <p>Sealevel hands off transactions to be executed using an industry-proven bytecode called the Berkeley Packet Filter (BPF), designed for high-performance packet filters. It can also be used for non-networking purposes. BPF and the extended BPF (eBPF) are in-kernel VMs available in most UNIX-like operating systems. They are very performant because their primary use was for packet matching, which needs to be as fast as possible. It also has decades of development behind it. The original version of BPF is now called classic BPF (cBPF), and this one could not be used for anything other than packet matching. The Linux kernel now includes only extended BPF (eBPF), a virtual machine with 64-bit registers. The eBPF is now called just BPF.</p> <p>It is worth mentioning that new modern firewalls are being built on top of the extended BPF.  BPF execution is currently parallelized only on the CPU level. What is used is a modified version of BPF called rBPF, which runs in the user space instead of the kernel. This was important as the kernel version of the BPF would not be able to facilitate certain operations.</p>"},{"location":"handbook/chapter3/tower-bft/","title":"Tower BFT (TBFT) \u2013\u2060 PoH-based PBFT","text":"<p>As a consensus algorithm, Solana uses the Tower BFT (TBFT), which is a custom implementation of the well-known Practical Byzantine Fault Tolerance (PBFT) algorithm published in 1999 by Miguel Castro and Barbara Liskov [6]. PBFT consensus rounds are divided into three main phases (pre-prepare, prepare and commit); see Figure 1.2. A detailed description is beyond the scope of this handbook.</p> <p></p> <p>PBFT is focused on satisfying the properties of safety (results are valid and identical at all non-faulty nodes) and liveness (nodes that don\u2019t fail always produce a result). The safety guarantee is possible due to the deterministic nature of the process (executed on every node). The liveness guarantee is possible due to the View-change process. The network will not be stopped unless there are too many byzantine nodes. View-change allows nodes to switch leaders if they appear to be malicious or faulty.</p>"},{"location":"handbook/chapter3/tower-bft/#view-change","title":"View-change","text":"<p>View-changes are carried out when a leader appears to have failed, and so another node attempts to take his place by initiating an election process. It gets triggered by timeouts that prevent nodes from waiting indefinitely for requests to execute. In addition, the timeout is postponed whenever the protocol detects that nodes are reaching an agreement on the current block.</p>"},{"location":"handbook/chapter3/tower-bft/#tbft-vs-pbft","title":"TBFT vs. PBFT","text":"<p>TBFT is a derivation of PBFT, which differs in one fundamental thing. PoH provides a global source of time before consensus is reached and can therefore be used to enforce the exponentially-increasing timeouts introduced in the original PBFT algorithm. No messages are needed as the PoH itself enforces them. The procedure is as follows. Voting on a new block is restricted to a fixed time period counted in hashes, this unit of time is called a slot. At the moment and with the current network settings, if we convert the number of PoH hashes to time, it is approximately 400ms for one slot. Thus every 400ms, a new potential rollback point occurs, but each new block that is voted on doubles the amount of time the network would have to stall before unrolling the original vote. Consider that each validator has voted 32 times in the last few ~12 seconds (32 \u00b7 0.4). The vote 12 seconds ago now has a timeout of 232 slots, which converted to years with a constant time of a slot of 400ms, is roughly 54 years (232 \u00b7 0.4/86400/365). A transaction with 32 confirmations is also considered finalized.</p>"},{"location":"handbook/chapter3/turbine/","title":"Turbine \u2013\u2060 Block Propagation Protocol","text":"<p>Turbine is a name for a smart block propagation protocol that reduces the time needed for block propagation and the overall message complexity reducing the communication overhead of a node.</p> <p>Turbine is a multi-layer propagation protocol. First, nodes in the network are divided into small partitions called neighborhoods. Nodes within a particular neighborhood are responsible for sharing received data with other nodes in the same neighborhood and propagating the data to a small number of nodes in other neighborhoods (Figure 1.3 and 1.4). The data unit shared is called a shred, and one block is constituted of many shreds.</p> <p>The partitioning of nodes into neighborhoods and how exactly are shreds shared within and out of their neighborhoods are implementation details.</p> <p>Since we are in an adversarial environment, any node can decide not to rebroadcast the received shreds or broadcast incorrect data.</p> <p>These two problems are solved with a series of countermeasures:</p> <ul> <li>Forward Error Code (FEC), specifically the Erasure Code, helps by broadcasting a block with more shreds than initially needed to reconstruct the entire block without errors, even if some shreds are lost along the way. With N = 6 data shreds and additional K = 3 shreds, we can lose up to 1/3 of the shreds and still be able to reconstruct the entire block fully.</li> <li>Propagation is prioritized according to their stake. Validators with the most stake are put closer to the current leader. A stake-weighted selection algorithm is used to create a tree where the risk of faulty or malicious nodes is minimized.</li> </ul> <p> </p>"},{"location":"handbook/chapter5/","title":"Solana Program Library","text":"<p>The Solana Program Library (SPL) [17] is a collection of on-chain programs such as SPL-Token that facilitates tasks such as creating and using tokens and a lot more.</p>"},{"location":"handbook/chapter5/account-compression-program/","title":"Account Compression Program","text":"<p>The Account Compression Program [21] is an innovative on-chain system designed to alleviate the rising concern of storage costs on the Solana blockchain. Its main application revolves around the utilization of SPL ConcurrentMerkleTrees, allowing for the on-chain verification of off-chain data edits. This innovative solution has been crafted in response to the challenges brought about by the increased creation of Non-Fungible Tokens (NFTs) on the Solana blockchain.</p>"},{"location":"handbook/chapter5/account-compression-program/#motivation","title":"Motivation","text":"<ul> <li>Solana's high throughput has fostered a significant increase in the creation of NFTs. The attractive features of NFTs, such as custodial ownership and censorship resistance, have contributed to their popularity. However, this widespread adoption has led to a critical concern: the network storage costs when creating NFTs at scale.</li> <li>While minting a single non-fungible token may be relatively inexpensive, the cost of storing the asset's data on-chain can quickly become uneconomical as the quantity increases. This issue presents a barrier to the practical and widespread use of NFTs, especially when they are produced en masse.</li> <li>The objective is to make the cost per token as close to zero as possible, ensuring affordability and scalability. The solution lies in storing a compressed hash of the asset data on-chain, while the actual data resides off-chain in a database.</li> <li>The Account Compression Program facilitates this by providing a means to verify the off-chain data on-chain and enabling concurrent writes to the data. A central component of this solution is the Concurrent Merkle Tree, a newly introduced data structure that prevents proof collision during concurrent writes.</li> </ul>"},{"location":"handbook/chapter5/account-compression-program/#application","title":"Application","text":"<p>The Account Compression Program is already in use in projects like the Metaplex Bubblegum Program. Its implementation has allowed for a reduction in on-chain storage costs, making it more economical to produce and manage NFTs at scale.</p>"},{"location":"handbook/chapter5/associated-token-acc-program/","title":"Associated Token Account Program","text":"<p>This program defines [19] the convention and provides the mechanism for mapping the user's wallet address to the associated token accounts they hold.</p>"},{"location":"handbook/chapter5/associated-token-acc-program/#motivation","title":"Motivation","text":"<ul> <li>A user may own arbitrarily many token accounts belonging to the same mint which makes it difficult for other users to know which account they should send tokens to and introduces friction into many other aspects of token management. This program introduces a way to deterministically derive a token account key from a user's main System account address and a token mint address, allowing the user to create a main token account for each token they own. We call these accounts Associated Token Accounts.</li> <li>In addition, it allows a user to send tokens to another user even if the beneficiary does not yet have a token account for that mint. Unlike a system transfer, for a token transfer to succeed the recipient must have a token account with the compatible mint already, and somebody needs to fund that token account. If the recipient must fund it first, it makes things like airdrop campaigns difficult and just generally increases the friction of token transfers. The Associated Token Account program allows the sender to create the associated token account for the receiver, so the token transfer just works.</li> </ul>"},{"location":"handbook/chapter5/token-2022/","title":"Token 2022 Program","text":"<p>The Token-2022 Program [20] extends the functionality provided by the Token Program. This means that the Token-2022 program is backward compatible and includes all the functions of the original Token program, as well as additional functionality often referred to as token extensions. You can think of the extensions as a series of options, features, and capabilities built into the newest iteration of the Solana token program.</p>"},{"location":"handbook/chapter5/token-2022/#benefits","title":"Benefits","text":"<ul> <li>Flexibility: Token issuers can choose to enable any combination of token extensions.</li> <li>Reduced risk: Using audited and well-tested extensions reduces attack vectors and helps to protect protocols and funds.</li> <li>Reduced testing costs: Because the extensions are added by simply specifying the extensions in your code, the chances of defects and human error are greatly reduced, saving on testing time and costs.</li> <li>Reduced development time: Because the extensions are uniform and reusable, the time required to develop applications using the extensions is significantly reduced.</li> </ul>"},{"location":"handbook/chapter5/token-2022/#extensions","title":"Extensions","text":"<p>Extensions can be of two types: mint and account extensions. All of these extensions can be used out-of-the-box.</p> <p>Mint extensions are added on top of the original Solana Token Program and extend the abilities of tokens. Account extensions are added on top of Solana accounts and add account-related features.</p> <p>Current mint extensions include 14 extensions. Some of the most important are:</p> <ul> <li>Confidential transfers: Allow confidential transfers between participating users without revealing the amount of the transfer.</li> <li>Transfer fees: Allow transfer fees to be charged on each transfer and sent to a defined account.</li> <li>Mint close authority: Allows owners to close mint accounts and reclaim the lamports on the mint account.</li> <li>Transfer hook: Allows calling specific programs with each token transfer.</li> </ul> <p>Current account extensions include:</p> <ul> <li>Memo required on transfer: Requires an attached memo as a message during each token transfer. This could be used for regulatory compliance, reporting, and enhanced audit trails. Immutable owner: Makes it impossible to reassign ownership of an account.</li> <li>Default account state: Freezes all new token accounts so that users must interact with the project in some way to unfreeze the accounts/tokens.</li> <li>CPI guard: Restricts how other programs can interact with your token by prohibiting certain actions inside cross-program invocations.</li> <li>Reallocate: Some extensions can be enabled after account creation. Reallocate allows owners in this situation to reallocate their token account to create room for more extensions. For a complete explanation and guide about the Token 2022 Program and its extensions see [20].</li> </ul>"},{"location":"handbook/chapter5/token-program/","title":"Token Program","text":"<p>A Token program [18] on the Solana blockchain. This program defines a common implementation for Fungible and Non Fungible tokens.</p> <p>All tokens on Solana, whether they are fungible tokens or NFTs (see Figure 1.9), are created using the SPL Token Program. If you\u2019re familiar with Ethereum, you can think of SPL tokens as a token standard such as ERC-20 or ERC-721. One key difference, however, is that Solana does not require you to deploy a new contract for each token you create. Instead, it simply requires you to send instructions to the Token Program and it will create and mint tokens on your behalf.</p> <p></p>"},{"location":"handbook/chapter5/token-program/#creating-a-new-token","title":"Creating a new Token","text":"<p>A new Token can be created [18] by initializing a new Mint with the InitializeMint instruction. The Mint is used to create or \"mint\" new tokens, and these tokens are stored in Accounts. A Mint is associated with each Account, which means that the total supply of a particular token type is equal to the balances of all the associated Accounts (see Figure 1.9 for mentioned fields).</p> <p>Once a Mint is initialized, the mint_authority can create new tokens using the MintTo instruction. As long as a Mint contains a valid mint_authority, the Mint is considered to have a non-fixed supply, and the mint_authority can create new tokens with the MintTo instruction at any time.</p>"},{"location":"handbook/chapter5/token-program/#transferring-tokens","title":"Transferring Tokens","text":"<p>Balances can be transferred [18] between Accounts using the Transfer instruction. The owner of the source Account must be present as a signer in the Transfer instruction when the source and destination accounts are different.</p> <p>The image provided below depicts the process of token transfer. Further information about Associated Token Accounts (ATA) will be covered in subsequent sections.</p>"},{"location":"handbook/chapter5/token-program/#burning-tokens","title":"Burning Tokens","text":"<p>The Burn instruction [18] decreases an Account's token balance without transferring to another Account, effectively removing the token from circulation permanently.</p> <p>There is no other way to reduce supply on chain. This is similar to transferring to an account with an unknown private key or destroying a private key. But the act of burning by using Burn instructions is more explicit and can be confirmed on chain by any parties.</p>"},{"location":"handbook/chapter5/token-program/#freezing-accounts","title":"Freezing Accounts","text":"<p>The Mint may also contain a freeze_authority which can be used [18] to issue FreezeAccount instructions that will render an Account unusable. Token instructions that include a frozen account will fail until the Account is thawed using the ThawAccount instruction. The SetAuthority instruction can be used to change a Mint's freeze_authority.</p>"},{"location":"handbook/chapter5/token-program/#wrapping-sol","title":"Wrapping Sol","text":"<p>The Token Program can be used [18] to wrap native SOL. Doing so allows native SOL to be treated like any other Token program token type and can be useful when being called from other programs that interact with the Token Program's interface.</p> <p>Accounts containing wrapped SOL are associated with a specific Mint called the \"Native Mint\"</p> <p>These accounts have a few unique behaviors:</p> <ul> <li>InitializeAccount sets the balance of the initialized Account to the SOL balance of the Solana account being initialized, resulting in a token balance equal to the SOL balance.</li> <li>Transfers to and from not only modify the token balance but also transfer an equal amount of SOL from the source account to the destination account.</li> <li>Burning is not supported</li> <li>When closing an Account the balance may be non-zero.</li> </ul>"},{"location":"handbook/chapter5/token-program/#non-fungible-tokens","title":"Non-Fungible Tokens","text":"<p>An NFT is simply a token type where only a single token has been minted. A more comprehensive discussion about NFTs is conducted in Appendix B.</p>"},{"location":"handbook/introduction/","title":"Introduction","text":"<p>The handbook is structured as follows:</p> <ul> <li>Beginning with Chapter 1, Blockchain Terminology, it clarifies fundamental concepts.</li> <li>Chapter 2, Solana Introduction, provides initial insights into Solana.</li> <li>Chapter 3, Solana Core Concepts, delves deeply into the platform's foundational ideas.</li> <li>Chapter 4, the Programming Model, talks about its operational framework.</li> <li>Continuing, Chapter 5, Solana Program Library discusses available resources provided by the Program Library.</li> </ul> <p>Appendices cover various domains:</p> <ul> <li>Appendix A - Ecosystem, introduces you into the Solana Ecosystem.</li> <li>Appendix B - NFT, provides technical insights into NFTs.</li> <li>Appendix C - Gaming, details about upcoming Web3 and Games.</li> </ul> <p>This comprehensive handbook functions as an ideal primer for those embarking on a journey to understand Solana. We wholeheartedly welcome any input, be it identifying errors or suggesting expansions, to enhance this resource.</p>"},{"location":"handbook/introduction/#why-solana-handbook","title":"Why Solana Handbook?","text":"<p>Solana was introduced by Anatoly Yakovenko in 2017 when the Solana Whitepaper [10] was published. However, the whitepaper is no longer up-to-date and we haven\u2019t found documentation that would meet our needs - to provide study material for the School of Solana. That is why this handbook was created. Its purpose is to introduce the reader to the Solana blockchain. It should serve as an entry point for new Solana developers or blockchain enthusiasts wishing to learn about Solana.</p>"},{"location":"handbook/introduction/#authors","title":"Authors","text":"<p>This handbook was created with love by Solana Auditors and Developers of Ackee. It is based on a master thesis of Luk\u00e1\u0161 Koz\u00e1k under the supervision of Josef Gattermayer, Ph.D., assistant professor at the Faculty of Information Technology, Czech Technical University in Prague and CEO of Ackee. Ackee is a blockchain security company founded in 2021, specializing in audits and other security assessments. Its team of experts performs Ethereum and Solana audits and develops open-source security frameworks Wake and Trident. By running free certification courses: the School of Solana and the School of Solidity, Ackee contributes to a stronger blockchain ecosystem by sharing knowledge.</p>"},{"location":"revisions/","title":"Document Revisions","text":"Revision Description Date 1.0 First version of the document published Jun 15, 2022 1.1 Added Chapters 6 and 7 Aug 30, 2022 1.2 Renaming and change of content in Chapter 2 Sep 27, 2022 1.3 Formatting and updated chapters Ecosystem, Gaming, Non-Fungible-Tokens and SPL Aug 29, 2023 1.4 Token 2022 and token extensions Mar 22, 2024"}]}